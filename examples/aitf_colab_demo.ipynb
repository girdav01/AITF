{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# AITF — AI Telemetry Framework\n",
    "\n",
    "## Interactive Demo on Google Colab\n",
    "\n",
    "**AITF** is a security-first telemetry framework for AI systems built on [OpenTelemetry](https://opentelemetry.io/) and [OCSF](https://ocsf.io/). It provides:\n",
    "\n",
    "| Capability | Description |\n",
    "|---|---|\n",
    "| **OCSF Category 7** | 8 AI event classes (7001–7008) for SIEM/XDR integration |\n",
    "| **12 Instrumentors** | LLM, Agent, MCP, RAG, Skills, ModelOps, Identity, and more |\n",
    "| **3 Exporters** | OCSF JSON, Immutable Audit Logs, CEF Syslog |\n",
    "| **4 Security Processors** | OWASP LLM Top 10, PII Redaction, Cost Tracking, Memory Monitoring |\n",
    "| **Vendor Mapping** | Declarative JSON mappings for LangChain, CrewAI, and custom frameworks |\n",
    "| **8 Compliance Frameworks** | NIST AI RMF, EU AI Act, MITRE ATLAS, ISO 42001, SOC2, GDPR, CCPA, CSA AICM |\n",
    "| **AI-BOM** | AI Bill of Materials generation in AITF, CycloneDX, and SPDX formats |\n",
    "\n",
    "This notebook walks through each capability interactively.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toc"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup & Installation](#setup)\n",
    "2. [OCSF Schema Explorer](#schema)\n",
    "3. [LLM Inference Tracing](#llm)\n",
    "4. [Agent Session Tracing](#agent)\n",
    "5. [Vendor Mapping — LangChain & CrewAI](#vendor)\n",
    "6. [Compliance Framework Mapping](#compliance)\n",
    "7. [Agentic Log Entries](#agentic-log)\n",
    "8. [AI-BOM Generation](#aibom)\n",
    "9. [Full Pipeline — End to End](#pipeline)\n",
    "10. [Export & Visualization](#viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 1. Setup & Installation <a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install AITF and dependencies\n",
    "# On Colab, this installs from the repo; locally you can use: pip install aitf\n",
    "import subprocess, sys\n",
    "\n",
    "# Clone the repo (Colab) or use local install\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab — installing from GitHub...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "                           \"opentelemetry-api\", \"opentelemetry-sdk\", \"pydantic>=2.0\"])\n",
    "    subprocess.check_call([\"git\", \"clone\", \"-q\", \"https://github.com/girdav01/AITF.git\", \"/content/AITF\"])\n",
    "    sys.path.insert(0, \"/content/AITF/sdk/python/src\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally.\")\n",
    "\n",
    "# Verify imports\n",
    "import aitf\n",
    "print(f\"\\nAITF version: {aitf.__version__}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "common-imports"
   },
   "outputs": [],
   "source": [
    "# Common imports used throughout the notebook\n",
    "import json\n",
    "from unittest.mock import MagicMock\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
    "\n",
    "# Pretty-print helper\n",
    "def pp(obj, title=None):\n",
    "    \"\"\"Pretty-print a dict or Pydantic model.\"\"\"\n",
    "    if title:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  {title}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    if hasattr(obj, 'model_dump'):\n",
    "        obj = obj.model_dump(exclude_none=True)\n",
    "    print(json.dumps(obj, indent=2, default=str))\n",
    "\n",
    "# Mock span helper (simulates what OpenTelemetry produces)\n",
    "def make_span(name, attributes=None):\n",
    "    \"\"\"Create a mock ReadableSpan for demonstration.\"\"\"\n",
    "    span = MagicMock()\n",
    "    span.name = name\n",
    "    span.attributes = attributes or {}\n",
    "    span.start_time = int(datetime.now(timezone.utc).timestamp() * 1e9)\n",
    "    return span\n",
    "\n",
    "print(\"Common imports loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "schema-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 2. OCSF Schema Explorer <a id=\"schema\"></a>\n",
    "\n",
    "AITF defines **Category 7: AI System Activity** in the OCSF schema with eight event classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "schema-explore"
   },
   "outputs": [],
   "source": [
    "from aitf.ocsf.schema import (\n",
    "    AIClassUID, AIBaseEvent, AIModelInfo, AITokenUsage,\n",
    "    AILatencyMetrics, AICostInfo, OCSFMetadata, OCSFSeverity,\n",
    "    ComplianceMetadata, AISecurityFinding,\n",
    ")\n",
    "from aitf.ocsf.event_classes import (\n",
    "    AIModelInferenceEvent, AIAgentActivityEvent, AIToolExecutionEvent,\n",
    "    AIDataRetrievalEvent, AISecurityFindingEvent, AISupplyChainEvent,\n",
    "    AIGovernanceEvent, AIIdentityEvent,\n",
    ")\n",
    "\n",
    "# Display all 8 OCSF Category 7 class UIDs\n",
    "print(\"OCSF Category 7 — AI System Activity\")\n",
    "print(\"=\" * 50)\n",
    "class_map = {\n",
    "    7001: (\"AI Model Inference\", AIModelInferenceEvent),\n",
    "    7002: (\"AI Agent Activity\", AIAgentActivityEvent),\n",
    "    7003: (\"AI Tool Execution\", AIToolExecutionEvent),\n",
    "    7004: (\"AI Data Retrieval\", AIDataRetrievalEvent),\n",
    "    7005: (\"AI Security Finding\", AISecurityFindingEvent),\n",
    "    7006: (\"AI Supply Chain\", AISupplyChainEvent),\n",
    "    7007: (\"AI Governance\", AIGovernanceEvent),\n",
    "    7008: (\"AI Identity\", AIIdentityEvent),\n",
    "}\n",
    "for uid, (name, cls) in class_map.items():\n",
    "    fields = [f for f in cls.model_fields if f not in AIBaseEvent.model_fields]\n",
    "    print(f\"\\n  {uid}: {name}\")\n",
    "    print(f\"         Fields: {', '.join(fields[:6])}{'...' if len(fields) > 6 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "schema-event-example"
   },
   "outputs": [],
   "source": [
    "# Create an OCSF event directly from Pydantic models\n",
    "event = AIModelInferenceEvent(\n",
    "    activity_id=1,  # chat\n",
    "    model=AIModelInfo(\n",
    "        model_id=\"claude-sonnet-4-5-20250929\",\n",
    "        provider=\"anthropic\",\n",
    "        type=\"llm\",\n",
    "    ),\n",
    "    token_usage=AITokenUsage(input_tokens=500, output_tokens=200),\n",
    "    latency=AILatencyMetrics(total_ms=1250.0, tokens_per_second=160.0),\n",
    "    cost=AICostInfo(input_cost_usd=0.0015, output_cost_usd=0.003, total_cost_usd=0.0045),\n",
    "    finish_reason=\"end_turn\",\n",
    "    streaming=True,\n",
    "    message=\"chat claude-sonnet-4-5-20250929\",\n",
    ")\n",
    "\n",
    "pp(event, \"OCSF 7001: AI Model Inference Event\")\n",
    "\n",
    "print(f\"\\n  class_uid:  {event.class_uid}\")\n",
    "print(f\"  type_uid:   {event.type_uid}  (class_uid * 100 + activity_id)\")\n",
    "print(f\"  category:   {event.category_uid}  (AI System Activity)\")\n",
    "print(f\"  tokens:     {event.token_usage.total_tokens}  ({event.token_usage.input_tokens} in + {event.token_usage.output_tokens} out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llm-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 3. LLM Inference Tracing <a id=\"llm\"></a>\n",
    "\n",
    "Trace LLM calls with the `OCSFMapper` — it converts OpenTelemetry spans to OCSF events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llm-mapper"
   },
   "outputs": [],
   "source": [
    "from aitf.ocsf.mapper import OCSFMapper\n",
    "\n",
    "mapper = OCSFMapper()\n",
    "\n",
    "# Simulate an OpenAI chat span\n",
    "chat_span = make_span(\"chat gpt-4o\", {\n",
    "    \"gen_ai.system\": \"openai\",\n",
    "    \"gen_ai.request.model\": \"gpt-4o\",\n",
    "    \"gen_ai.operation.name\": \"chat\",\n",
    "    \"gen_ai.request.temperature\": 0.7,\n",
    "    \"gen_ai.request.max_tokens\": 4096,\n",
    "    \"gen_ai.usage.input_tokens\": 350,\n",
    "    \"gen_ai.usage.output_tokens\": 180,\n",
    "    \"gen_ai.response.finish_reasons\": [\"stop\"],\n",
    "    \"aitf.latency.total_ms\": 920.5,\n",
    "    \"aitf.latency.tokens_per_second\": 195.6,\n",
    "    \"aitf.cost.total_cost\": 0.00265,\n",
    "    \"aitf.cost.input_cost\": 0.000875,\n",
    "    \"aitf.cost.output_cost\": 0.0018,\n",
    "})\n",
    "\n",
    "event = mapper.map_span(chat_span)\n",
    "pp(event, \"LLM Inference -> OCSF 7001\")\n",
    "\n",
    "# Simulate an embeddings span\n",
    "embed_span = make_span(\"embeddings text-embedding-3-small\", {\n",
    "    \"gen_ai.system\": \"openai\",\n",
    "    \"gen_ai.request.model\": \"text-embedding-3-small\",\n",
    "    \"gen_ai.operation.name\": \"embeddings\",\n",
    "    \"gen_ai.usage.input_tokens\": 42,\n",
    "})\n",
    "\n",
    "event2 = mapper.map_span(embed_span)\n",
    "print(f\"\\nEmbeddings event class_uid: {event2.class_uid}, activity_id: {event2.activity_id}\")\n",
    "print(f\"Model type: {event2.model.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agent-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 4. Agent Session Tracing <a id=\"agent\"></a>\n",
    "\n",
    "Map agent lifecycle spans (session start, step execute, delegation, memory access) to OCSF 7002."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agent-mapper"
   },
   "outputs": [],
   "source": [
    "# Agent step execution\n",
    "agent_span = make_span(\"agent.step.planning\", {\n",
    "    \"aitf.agent.name\": \"research-agent\",\n",
    "    \"aitf.agent.id\": \"agent-001\",\n",
    "    \"aitf.agent.session_id\": \"sess-abc123\",\n",
    "    \"aitf.agent.type\": \"autonomous\",\n",
    "    \"aitf.agent.framework\": \"crewai\",\n",
    "    \"aitf.agent.step.type\": \"planning\",\n",
    "    \"aitf.agent.step.index\": 1,\n",
    "    \"aitf.agent.step.thought\": \"I need to search for AI security papers first.\",\n",
    "    \"aitf.agent.step.action\": \"call_tool:web-search\",\n",
    "})\n",
    "\n",
    "event = mapper.map_span(agent_span)\n",
    "pp(event, \"Agent Step -> OCSF 7002\")\n",
    "\n",
    "# Agent delegation\n",
    "delegation_span = make_span(\"agent.delegation\", {\n",
    "    \"aitf.agent.name\": \"manager\",\n",
    "    \"aitf.agent.id\": \"agent-mgr\",\n",
    "    \"aitf.agent.session_id\": \"sess-abc123\",\n",
    "    \"aitf.agent.delegation.target_agent\": \"researcher\",\n",
    "})\n",
    "\n",
    "event2 = mapper.map_span(delegation_span)\n",
    "print(f\"\\nDelegation: activity_id={event2.activity_id} (4=Delegation)\")\n",
    "print(f\"From: {event2.agent_name} -> To: {event2.delegation_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tool-mapper"
   },
   "outputs": [],
   "source": [
    "# MCP tool execution -> OCSF 7003\n",
    "tool_span = make_span(\"mcp.tool.search_knowledge_base\", {\n",
    "    \"aitf.mcp.tool.name\": \"search_knowledge_base\",\n",
    "    \"aitf.mcp.tool.server\": \"kb-server\",\n",
    "    \"aitf.mcp.server.transport\": \"stdio\",\n",
    "    \"aitf.mcp.tool.input\": '{\"query\": \"AI telemetry best practices\"}',\n",
    "    \"aitf.mcp.tool.output\": '[{\"title\": \"AITF Guide\", \"score\": 0.95}]',\n",
    "    \"aitf.mcp.tool.duration_ms\": 245.3,\n",
    "    \"aitf.mcp.tool.is_error\": False,\n",
    "    \"aitf.mcp.tool.approval_required\": True,\n",
    "    \"aitf.mcp.tool.approved\": True,\n",
    "})\n",
    "\n",
    "event = mapper.map_span(tool_span)\n",
    "pp(event, \"MCP Tool Execution -> OCSF 7003\")\n",
    "\n",
    "# RAG retrieval -> OCSF 7004\n",
    "rag_span = make_span(\"rag.retrieve\", {\n",
    "    \"aitf.rag.retrieve.database\": \"pinecone\",\n",
    "    \"aitf.rag.query\": \"What are the OWASP LLM Top 10?\",\n",
    "    \"aitf.rag.retrieve.top_k\": 10,\n",
    "    \"aitf.rag.retrieve.results_count\": 8,\n",
    "    \"aitf.rag.retrieve.min_score\": 0.72,\n",
    "    \"aitf.rag.retrieve.max_score\": 0.98,\n",
    "    \"aitf.rag.pipeline.name\": \"security-qa\",\n",
    "    \"aitf.rag.pipeline.stage\": \"retrieve\",\n",
    "    \"aitf.rag.query.embedding_model\": \"text-embedding-3-large\",\n",
    "})\n",
    "\n",
    "event2 = mapper.map_span(rag_span)\n",
    "pp(event2, \"RAG Retrieval -> OCSF 7004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vendor-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 5. Vendor Mapping — LangChain & CrewAI <a id=\"vendor\"></a>\n",
    "\n",
    "Vendors supply **JSON mapping files** that translate their native telemetry to AITF conventions. No custom code needed — the `VendorMapper` loads the JSON and handles everything.\n",
    "\n",
    "```\n",
    "Vendor Telemetry  -->  VendorMapper  -->  OCSFMapper  -->  SIEM\n",
    "(native attrs)        (JSON-driven)      (standard)       (OCSF)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vendor-setup"
   },
   "outputs": [],
   "source": [
    "from aitf.ocsf.vendor_mapper import VendorMapper\n",
    "\n",
    "vendor_mapper = VendorMapper()\n",
    "\n",
    "print(\"Loaded Vendor Mappings\")\n",
    "print(\"=\" * 60)\n",
    "for info in vendor_mapper.list_supported_vendors():\n",
    "    print(f\"\\n  Vendor:      {info['vendor']}\")\n",
    "    print(f\"  Version:     {info['version']}\")\n",
    "    print(f\"  Event Types: {info['event_types']}\")\n",
    "    print(f\"  Description: {info['description'][:70]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vendor-langchain"
   },
   "outputs": [],
   "source": [
    "# --- LangChain: ChatOpenAI inference ---\n",
    "\n",
    "lc_inference = make_span(\"ChatOpenAI\", {\n",
    "    \"ls_provider\": \"openai\",\n",
    "    \"ls_model_name\": \"gpt-4o\",\n",
    "    \"ls_temperature\": 0.7,\n",
    "    \"llm.token_count.prompt\": 250,\n",
    "    \"llm.token_count.completion\": 180,\n",
    "    \"llm.token_count.total\": 430,\n",
    "})\n",
    "\n",
    "result = vendor_mapper.normalize_span(lc_inference)\n",
    "vendor, event_type, aitf_attrs = result\n",
    "\n",
    "print(\"LangChain ChatOpenAI -> AITF Normalization\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Detected Vendor: {vendor}\")\n",
    "print(f\"  Event Type:      {event_type}\")\n",
    "print(f\"  OCSF Class UID:  {vendor_mapper.get_ocsf_class_uid(vendor, event_type)}\")\n",
    "print(f\"\\n  Attribute Translation:\")\n",
    "print(f\"    ls_provider         -> gen_ai.system         = {aitf_attrs.get('gen_ai.system')}\")\n",
    "print(f\"    ls_model_name       -> gen_ai.request.model  = {aitf_attrs.get('gen_ai.request.model')}\")\n",
    "print(f\"    ls_temperature      -> gen_ai.request.temp   = {aitf_attrs.get('gen_ai.request.temperature')}\")\n",
    "print(f\"    llm.token_count.*   -> gen_ai.usage.*        = {aitf_attrs.get('gen_ai.usage.input_tokens')} in / {aitf_attrs.get('gen_ai.usage.output_tokens')} out\")\n",
    "\n",
    "# --- LangChain: Vector Store Retriever ---\n",
    "\n",
    "lc_rag = make_span(\"VectorStoreRetriever\", {\n",
    "    \"langchain.retriever.name\": \"pinecone-kb\",\n",
    "    \"langchain.retriever.type\": \"pinecone\",\n",
    "    \"langchain.retriever.k\": 10,\n",
    "    \"langchain.retriever.query\": \"AI security best practices\",\n",
    "    \"langchain.retriever.documents\": 8,\n",
    "})\n",
    "\n",
    "result = vendor_mapper.normalize_span(lc_rag)\n",
    "print(f\"\\n\\nLangChain Retriever -> {result[1]} (OCSF {vendor_mapper.get_ocsf_class_uid(*result[:2])})\")\n",
    "print(\"  Translated attributes:\")\n",
    "for k, v in sorted(result[2].items()):\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vendor-crewai"
   },
   "outputs": [],
   "source": [
    "# --- CrewAI: Agent Execution ---\n",
    "\n",
    "crew_agent = make_span(\"Agent Execution\", {\n",
    "    \"crewai.agent.role\": \"security-researcher\",\n",
    "    \"crewai.agent.goal\": \"Analyze threat intelligence reports\",\n",
    "    \"crewai.agent.id\": \"agent-sec-001\",\n",
    "    \"crewai.agent.llm\": \"claude-sonnet-4-5-20250929\",\n",
    "    \"crewai.agent.tools\": \"web_search,file_read,code_analysis\",\n",
    "    \"crewai.crew.name\": \"threat-intel-crew\",\n",
    "    \"crewai.crew.process\": \"hierarchical\",\n",
    "})\n",
    "\n",
    "result = vendor_mapper.normalize_span(crew_agent)\n",
    "vendor, event_type, aitf_attrs = result\n",
    "\n",
    "print(\"CrewAI Agent Execution -> AITF Normalization\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Vendor: {vendor}, Event: {event_type}, OCSF: {vendor_mapper.get_ocsf_class_uid(vendor, event_type)}\")\n",
    "print(f\"\\n  CrewAI-specific translations:\")\n",
    "print(f\"    crewai.agent.role    -> aitf.agent.name          = {aitf_attrs.get('aitf.agent.name')}\")\n",
    "print(f\"    crewai.crew.name     -> aitf.agent.team.name     = {aitf_attrs.get('aitf.agent.team.name')}\")\n",
    "print(f\"    crewai.crew.process  -> aitf.agent.team.topology = {aitf_attrs.get('aitf.agent.team.topology')}\")\n",
    "print(f\"    (default)            -> aitf.agent.framework     = {aitf_attrs.get('aitf.agent.framework')}\")\n",
    "\n",
    "# --- CrewAI: Task Delegation ---\n",
    "\n",
    "crew_delegation = make_span(\"Task Delegation\", {\n",
    "    \"crewai.delegation.from_agent\": \"team-lead\",\n",
    "    \"crewai.delegation.to_agent\": \"security-researcher\",\n",
    "    \"crewai.delegation.task\": \"Investigate CVE-2024-1234\",\n",
    "    \"crewai.delegation.reason\": \"Specialized security knowledge\",\n",
    "})\n",
    "\n",
    "result = vendor_mapper.normalize_span(crew_delegation)\n",
    "print(f\"\\n\\nCrewAI Delegation -> {result[1]} (OCSF {vendor_mapper.get_ocsf_class_uid(*result[:2])})\")\n",
    "for k, v in sorted(result[2].items()):\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vendor-custom"
   },
   "outputs": [],
   "source": [
    "# --- Load a custom vendor mapping at runtime ---\n",
    "\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "autogen_mapping = {\n",
    "    \"vendor\": \"autogen\",\n",
    "    \"version\": \"0.4\",\n",
    "    \"description\": \"Maps Microsoft AutoGen telemetry to AITF conventions\",\n",
    "    \"homepage\": \"https://microsoft.github.io/autogen/\",\n",
    "    \"span_name_patterns\": {\n",
    "        \"inference\": [\"^AutoGen\\\\.LLM\", \"^AutoGen\\\\.ChatCompletion\"],\n",
    "        \"agent\": [\"^AutoGen\\\\.Agent\", \"^AutoGen\\\\.GroupChat\"],\n",
    "    },\n",
    "    \"attribute_mappings\": {\n",
    "        \"inference\": {\n",
    "            \"vendor_to_aitf\": {\n",
    "                \"autogen.llm.model\": \"gen_ai.request.model\",\n",
    "                \"autogen.llm.provider\": \"gen_ai.system\",\n",
    "                \"autogen.llm.input_tokens\": \"gen_ai.usage.input_tokens\",\n",
    "                \"autogen.llm.output_tokens\": \"gen_ai.usage.output_tokens\",\n",
    "            },\n",
    "            \"ocsf_class_uid\": 7001,\n",
    "            \"ocsf_activity_id_map\": {\"chat\": 1, \"default\": 1},\n",
    "            \"defaults\": {\"gen_ai.operation.name\": \"chat\"},\n",
    "        },\n",
    "        \"agent\": {\n",
    "            \"vendor_to_aitf\": {\n",
    "                \"autogen.agent.name\": \"aitf.agent.name\",\n",
    "                \"autogen.agent.type\": \"aitf.agent.type\",\n",
    "                \"autogen.group.name\": \"aitf.agent.team.name\",\n",
    "            },\n",
    "            \"ocsf_class_uid\": 7002,\n",
    "            \"ocsf_activity_id_map\": {\"default\": 3},\n",
    "            \"defaults\": {\"aitf.agent.framework\": \"autogen\"},\n",
    "        },\n",
    "    },\n",
    "    \"provider_detection\": {\n",
    "        \"attribute_keys\": [\"autogen.llm.provider\"],\n",
    "        \"model_prefix_to_provider\": {\"gpt-\": \"openai\", \"claude-\": \"anthropic\"},\n",
    "    },\n",
    "    \"severity_mapping\": {},\n",
    "    \"metadata\": {\n",
    "        \"ocsf_product\": {\"name\": \"AutoGen\", \"vendor_name\": \"Microsoft\", \"version\": \"0.4\"},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Write to temp file and load\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n",
    "    json.dump(autogen_mapping, f)\n",
    "    tmp_path = f.name\n",
    "\n",
    "vendor_mapper.load_file(tmp_path)\n",
    "\n",
    "print(\"Custom Vendor Mapping Loaded\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Total vendors: {len(vendor_mapper.vendors)}\")\n",
    "print(f\"  Vendors: {', '.join(vendor_mapper.vendors)}\")\n",
    "\n",
    "# Test AutoGen span\n",
    "autogen_span = make_span(\"AutoGen.Agent.execute\", {\n",
    "    \"autogen.agent.name\": \"code-reviewer\",\n",
    "    \"autogen.agent.type\": \"assistant\",\n",
    "    \"autogen.group.name\": \"dev-team\",\n",
    "})\n",
    "\n",
    "result = vendor_mapper.normalize_span(autogen_span)\n",
    "print(f\"\\n  AutoGen span detected: {result[0]}/{result[1]}\")\n",
    "print(f\"  Translated attributes:\")\n",
    "for k, v in sorted(result[2].items()):\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compliance-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 6. Compliance Framework Mapping <a id=\"compliance\"></a>\n",
    "\n",
    "AITF maps every AI event to controls from **8 regulatory frameworks** automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compliance-mapper"
   },
   "outputs": [],
   "source": [
    "from aitf.ocsf.compliance_mapper import ComplianceMapper\n",
    "\n",
    "compliance_mapper = ComplianceMapper()\n",
    "\n",
    "# Map model_inference to all 8 frameworks\n",
    "compliance = compliance_mapper.map_event(\"model_inference\")\n",
    "\n",
    "print(\"Compliance Mapping: model_inference\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "frameworks = [\n",
    "    (\"NIST AI RMF\", compliance.nist_ai_rmf),\n",
    "    (\"MITRE ATLAS\", compliance.mitre_atlas),\n",
    "    (\"ISO 42001\", compliance.iso_42001),\n",
    "    (\"EU AI Act\", compliance.eu_ai_act),\n",
    "    (\"SOC 2\", compliance.soc2),\n",
    "    (\"GDPR\", compliance.gdpr),\n",
    "    (\"CCPA\", compliance.ccpa),\n",
    "    (\"CSA AICM\", compliance.csa_aicm),\n",
    "]\n",
    "\n",
    "for name, data in frameworks:\n",
    "    if data:\n",
    "        # Get the primary control list\n",
    "        controls = data.get(\"controls\") or data.get(\"techniques\") or data.get(\"articles\") or data.get(\"sections\") or []\n",
    "        display = controls[:5]\n",
    "        suffix = f\" (+{len(controls)-5} more)\" if len(controls) > 5 else \"\"\n",
    "        print(f\"  {name:15s} {', '.join(str(c) for c in display)}{suffix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compliance-matrix"
   },
   "outputs": [],
   "source": [
    "# Coverage matrix — which frameworks apply to each event type\n",
    "matrix = compliance_mapper.get_coverage_matrix()\n",
    "\n",
    "print(\"Compliance Coverage Matrix\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "header_fw = [\"nist\", \"atlas\", \"iso\", \"eu_ai\", \"soc2\", \"gdpr\", \"ccpa\", \"aicm\"]\n",
    "fw_keys = [\"nist_ai_rmf\", \"mitre_atlas\", \"iso_42001\", \"eu_ai_act\", \"soc2\", \"gdpr\", \"ccpa\", \"csa_aicm\"]\n",
    "\n",
    "print(f\"  {'Event Type':22s} {' '.join(f'{h:>6s}' for h in header_fw)}  Total\")\n",
    "print(f\"  {'-'*22} {' '.join(['------'] * 8)}  -----\")\n",
    "\n",
    "for event_type, fw_map in matrix.items():\n",
    "    counts = []\n",
    "    total = 0\n",
    "    for fk in fw_keys:\n",
    "        n = len(fw_map.get(fk, []))\n",
    "        counts.append(n)\n",
    "        total += n\n",
    "    print(f\"  {event_type:22s} {' '.join(f'{c:6d}' for c in counts)}  {total:5d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compliance-enrich"
   },
   "outputs": [],
   "source": [
    "# Enrich an OCSF event with compliance metadata\n",
    "event = AIModelInferenceEvent(\n",
    "    activity_id=1,\n",
    "    model=AIModelInfo(model_id=\"gpt-4o\", provider=\"openai\"),\n",
    "    token_usage=AITokenUsage(input_tokens=100, output_tokens=50),\n",
    "    finish_reason=\"stop\",\n",
    ")\n",
    "\n",
    "enriched = compliance_mapper.enrich_event(event, \"model_inference\")\n",
    "\n",
    "print(\"Enriched OCSF Event (with compliance)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Event class: {enriched.class_uid} ({enriched.message or 'model_inference'})\")\n",
    "print(f\"  Has compliance: {enriched.compliance is not None}\")\n",
    "print(f\"  NIST controls: {enriched.compliance.nist_ai_rmf}\")\n",
    "print(f\"  EU AI Act:     {enriched.compliance.eu_ai_act}\")\n",
    "\n",
    "# Generate audit record\n",
    "audit = compliance_mapper.generate_audit_record(\n",
    "    event_type=\"model_inference\",\n",
    "    actor=\"analyst@example.com\",\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "pp(audit, \"Audit Record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agentic-log-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 7. Agentic Log Entries <a id=\"agentic-log\"></a>\n",
    "\n",
    "Structured log entries that capture security-relevant context for every AI agent action, based on the **Table 10.1 minimal fields** specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agentic-log-demo"
   },
   "outputs": [],
   "source": [
    "from aitf.instrumentation.agentic_log import AgenticLogInstrumentor\n",
    "\n",
    "provider = TracerProvider()\n",
    "provider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))\n",
    "trace.set_tracer_provider(provider)\n",
    "\n",
    "agentic_log = AgenticLogInstrumentor(tracer_provider=provider)\n",
    "\n",
    "# Table 10.1 example: Logi-Agent\n",
    "print(\"Agentic Log Entry (Table 10.1 Minimal Fields)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with agentic_log.log_action(\n",
    "    agent_id=\"agent-innovacorp-logicore-prod-042\",\n",
    "    session_id=\"sess-f0a1b2\",\n",
    "    event_id=\"e-44b1c8f0\",\n",
    ") as entry:\n",
    "    entry.set_goal_id(\"goal-resolve-port-congestion-sg\")\n",
    "    entry.set_sub_task_id(\"task-find-all-trucking-vendor\")\n",
    "    entry.set_tool_used(\"mcp.server.github.list_tools\")\n",
    "    entry.set_tool_parameters({\"repo\": \"innovacorp logistics-tools\"})\n",
    "    entry.set_outcome(\"SUCCESS\")\n",
    "    entry.set_confidence_score(0.92)\n",
    "    entry.set_anomaly_score(0.15)\n",
    "    entry.set_policy_evaluation({\n",
    "        \"policy\": \"max_spend\",\n",
    "        \"shipment\": True,\n",
    "        \"result\": \"PASS\",\n",
    "    })\n",
    "\n",
    "print(f\"\\n  Event ID:        {entry.event_id}\")\n",
    "print(f\"  Timestamp:       {entry.timestamp}\")\n",
    "print(f\"  Agent ID:        agent-innovacorp-logicore-prod-042\")\n",
    "print(f\"  Goal:            goal-resolve-port-congestion-sg\")\n",
    "print(f\"  Tool:            mcp.server.github.list_tools\")\n",
    "print(f\"  Outcome:         SUCCESS\")\n",
    "print(f\"  Confidence:      0.92\")\n",
    "print(f\"  Anomaly Score:   0.15  (low = normal)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agentic-log-anomaly"
   },
   "outputs": [],
   "source": [
    "# High anomaly score — demonstrates alerting threshold\n",
    "print(\"Agentic Log: Anomalous Action Detected\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with agentic_log.log_action(\n",
    "    agent_id=\"agent-innovacorp-sco-prod-007\",\n",
    "    session_id=\"sess-d3e4f5\",\n",
    "    goal_id=\"goal-optimize-asia-pacific-routes\",\n",
    "    sub_task_id=\"task-update-vendor-contract\",\n",
    "    tool_used=\"mcp.server.vendor-db.update_contract\",\n",
    "    tool_parameters={\"vendor_id\": \"VENDOR-TRK-042\", \"field\": \"rate_per_km\"},\n",
    ") as entry:\n",
    "    entry.set_outcome(\"DENIED\")\n",
    "    entry.set_confidence_score(0.30)\n",
    "    entry.set_anomaly_score(0.85)\n",
    "    entry.set_policy_evaluation({\n",
    "        \"policy\": \"write_access_contract\",\n",
    "        \"result\": \"FAIL\",\n",
    "        \"reason\": \"Agent lacks write permissions to vendor contracts\",\n",
    "    })\n",
    "\n",
    "print(f\"\\n  Outcome:       DENIED\")\n",
    "print(f\"  Confidence:    0.30  (low confidence)\")\n",
    "print(f\"  Anomaly:       0.85  (HIGH — would trigger SIEM alert)\")\n",
    "print(f\"  Policy:        FAIL  (write_access_contract)\")\n",
    "print(f\"\\n  This entry would generate a security finding in production.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aibom-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 8. AI-BOM Generation <a id=\"aibom\"></a>\n",
    "\n",
    "Generate an **AI Bill of Materials** from telemetry — automatically discovers models, tools, and frameworks in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aibom-demo"
   },
   "outputs": [],
   "source": [
    "from aitf.generators.ai_bom import AIBOMGenerator\n",
    "\n",
    "bom = AIBOMGenerator(\n",
    "    system_name=\"threat-intel-platform\",\n",
    "    system_version=\"3.0.0\",\n",
    ")\n",
    "\n",
    "# Register components (in production, these are auto-discovered from spans)\n",
    "bom.add_component(\"model\", \"claude-sonnet-4-5-20250929\", \"20250929\", provider=\"Anthropic\", license=\"Commercial\")\n",
    "bom.add_component(\"model\", \"gpt-4o\", \"2025-01-01\", provider=\"OpenAI\", license=\"Commercial\")\n",
    "bom.add_component(\"model\", \"text-embedding-3-large\", \"2024-01-25\", provider=\"OpenAI\", license=\"Commercial\")\n",
    "bom.add_component(\"framework\", \"crewai\", \"0.100.0\", provider=\"CrewAI Inc.\", license=\"MIT\")\n",
    "bom.add_component(\"framework\", \"langchain\", \"0.3.0\", provider=\"LangChain\", license=\"MIT\")\n",
    "bom.add_component(\"vector_store\", \"pinecone\", \"3.0.0\", provider=\"Pinecone\")\n",
    "bom.add_component(\"tool\", \"web-search-mcp\", \"1.2.0\", provider=\"internal\")\n",
    "bom.add_component(\"guardrail\", \"content-filter\", \"2.1\", provider=\"internal\")\n",
    "bom.add_component(\"prompt_template\", \"threat-analysis-v3\", \"3.0\", provider=\"internal\")\n",
    "\n",
    "# Add a known vulnerability\n",
    "bom.add_vulnerability(\n",
    "    \"framework\", \"langchain\", \"CVE-2024-EXAMPLE\",\n",
    "    severity=\"medium\", description=\"Demo vulnerability\",\n",
    ")\n",
    "\n",
    "print(\"AI-BOM Component Summary\")\n",
    "print(\"=\" * 60)\n",
    "summary = bom.get_component_summary()\n",
    "pp(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aibom-formats"
   },
   "outputs": [],
   "source": [
    "# Generate in multiple formats\n",
    "doc = bom.generate(bom_id=\"bom-tip-2025-001\")\n",
    "\n",
    "print(f\"AI-BOM Document\")\n",
    "print(f\"  ID:              {doc.bom_id}\")\n",
    "print(f\"  Components:      {doc.component_count}\")\n",
    "print(f\"  Types:           {doc.component_types}\")\n",
    "print(f\"  Vulnerabilities: {len(doc.vulnerabilities)}\")\n",
    "\n",
    "# CycloneDX format\n",
    "cdx = doc.to_cyclonedx()\n",
    "print(f\"\\nCycloneDX Export\")\n",
    "print(f\"  bomFormat:       {cdx['bomFormat']}\")\n",
    "print(f\"  specVersion:     {cdx['specVersion']}\")\n",
    "print(f\"  components:      {len(cdx['components'])}\")\n",
    "\n",
    "# SPDX format\n",
    "spdx = doc.to_spdx()\n",
    "print(f\"\\nSPDX Export\")\n",
    "print(f\"  spdxVersion:     {spdx['spdxVersion']}\")\n",
    "print(f\"  packages:        {len(spdx['packages'])}\")\n",
    "\n",
    "# Show one component in detail\n",
    "print(f\"\\nSample Component (CycloneDX):\")\n",
    "pp(cdx['components'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pipeline-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 9. Full Pipeline — End to End <a id=\"pipeline\"></a>\n",
    "\n",
    "Demonstrates the complete flow:\n",
    "\n",
    "```\n",
    "LangChain Span --> VendorMapper --> OCSFMapper --> ComplianceMapper --> OCSF Event\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pipeline-demo"
   },
   "outputs": [],
   "source": [
    "from aitf.ocsf.vendor_mapper import VendorMapper\n",
    "from aitf.ocsf.mapper import OCSFMapper\n",
    "from aitf.ocsf.compliance_mapper import ComplianceMapper\n",
    "\n",
    "# Initialize the pipeline\n",
    "vendor_mapper = VendorMapper()\n",
    "ocsf_mapper = OCSFMapper()\n",
    "compliance_mapper = ComplianceMapper(frameworks=[\"nist_ai_rmf\", \"eu_ai_act\", \"csa_aicm\"])\n",
    "\n",
    "# Simulate a LangChain inference span with vendor-native attributes\n",
    "raw_span = make_span(\"ChatAnthropic\", {\n",
    "    \"ls_provider\": \"anthropic\",\n",
    "    \"ls_model_name\": \"claude-sonnet-4-5-20250929\",\n",
    "    \"ls_temperature\": 0.5,\n",
    "    \"llm.token_count.prompt\": 500,\n",
    "    \"llm.token_count.completion\": 300,\n",
    "    \"llm.token_count.total\": 800,\n",
    "})\n",
    "\n",
    "print(\"Full Pipeline Execution\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Step 1: Vendor normalization\n",
    "norm = vendor_mapper.normalize_span(raw_span)\n",
    "vendor, event_type, aitf_attrs = norm\n",
    "print(f\"\\n  Step 1 — Vendor Detection\")\n",
    "print(f\"    Vendor:     {vendor}\")\n",
    "print(f\"    Event Type: {event_type}\")\n",
    "print(f\"    Attributes: {len(aitf_attrs)} AITF keys\")\n",
    "\n",
    "# Step 2: Create a normalized span and map to OCSF\n",
    "normalized_span = make_span(f\"chat {aitf_attrs.get('gen_ai.request.model', 'unknown')}\", aitf_attrs)\n",
    "ocsf_event = ocsf_mapper.map_span(normalized_span)\n",
    "\n",
    "print(f\"\\n  Step 2 — OCSF Mapping\")\n",
    "print(f\"    Class UID:   {ocsf_event.class_uid}  (AI Model Inference)\")\n",
    "print(f\"    Type UID:    {ocsf_event.type_uid}\")\n",
    "print(f\"    Activity:    {ocsf_event.activity_id}  (chat)\")\n",
    "print(f\"    Model:       {ocsf_event.model.model_id}\")\n",
    "print(f\"    Provider:    {ocsf_event.model.provider}\")\n",
    "print(f\"    Tokens:      {ocsf_event.token_usage.total_tokens}\")\n",
    "\n",
    "# Step 3: Compliance enrichment\n",
    "enriched = compliance_mapper.enrich_event(ocsf_event, \"model_inference\")\n",
    "\n",
    "print(f\"\\n  Step 3 — Compliance Enrichment\")\n",
    "print(f\"    NIST AI RMF: {enriched.compliance.nist_ai_rmf['controls']}\")\n",
    "print(f\"    EU AI Act:   {enriched.compliance.eu_ai_act['articles']}\")\n",
    "csa = enriched.compliance.csa_aicm\n",
    "print(f\"    CSA AICM:    {len(csa['controls'])} controls across {csa['domains']}\")\n",
    "\n",
    "# Final serialized event\n",
    "final = enriched.model_dump(exclude_none=True)\n",
    "print(f\"\\n  Final OCSF event: {len(json.dumps(final))} bytes\")\n",
    "print(f\"  Top-level keys: {list(final.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pipeline-crewai"
   },
   "outputs": [],
   "source": [
    "# Full pipeline with CrewAI multi-agent scenario\n",
    "\n",
    "spans = [\n",
    "    (\"Crew Execution\", {\n",
    "        \"crewai.agent.role\": \"manager\",\n",
    "        \"crewai.agent.id\": \"agent-mgr-001\",\n",
    "        \"crewai.crew.name\": \"security-audit-crew\",\n",
    "        \"crewai.crew.process\": \"hierarchical\",\n",
    "    }),\n",
    "    (\"LLM Call gpt-4o\", {\n",
    "        \"crewai.llm.model\": \"gpt-4o\",\n",
    "        \"crewai.llm.provider\": \"openai\",\n",
    "        \"crewai.llm.input_tokens\": 800,\n",
    "        \"crewai.llm.output_tokens\": 400,\n",
    "    }),\n",
    "    (\"Tool Execution web_search\", {\n",
    "        \"crewai.tool.name\": \"web_search\",\n",
    "        \"crewai.tool.input\": '{\"query\": \"latest CVEs\"}',\n",
    "        \"crewai.tool.output\": \"Found 12 results\",\n",
    "        \"crewai.tool.duration_ms\": 890.0,\n",
    "    }),\n",
    "    (\"Task Delegation\", {\n",
    "        \"crewai.delegation.from_agent\": \"manager\",\n",
    "        \"crewai.delegation.to_agent\": \"pen-tester\",\n",
    "        \"crewai.delegation.task\": \"Verify CVE exploitability\",\n",
    "    }),\n",
    "]\n",
    "\n",
    "print(\"CrewAI Multi-Agent Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "events_collected = []\n",
    "for span_name, attrs in spans:\n",
    "    span = make_span(span_name, attrs)\n",
    "\n",
    "    # Vendor normalize\n",
    "    result = vendor_mapper.normalize_span(span)\n",
    "    if result:\n",
    "        vendor, etype, aitf_a = result\n",
    "        class_uid = vendor_mapper.get_ocsf_class_uid(vendor, etype)\n",
    "        events_collected.append({\n",
    "            \"span\": span_name,\n",
    "            \"vendor\": vendor,\n",
    "            \"event_type\": etype,\n",
    "            \"ocsf_class\": class_uid,\n",
    "            \"aitf_keys\": len(aitf_a),\n",
    "        })\n",
    "        print(f\"\\n  {span_name}\")\n",
    "        print(f\"    -> {vendor}/{etype} -> OCSF {class_uid} | {len(aitf_a)} AITF attrs\")\n",
    "\n",
    "print(f\"\\n  Total events: {len(events_collected)}\")\n",
    "print(f\"  Event types: {set(e['event_type'] for e in events_collected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viz-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 10. Export & Visualization <a id=\"viz\"></a>\n",
    "\n",
    "Visualize the OCSF events as a formatted table and export as JSONL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-events"
   },
   "outputs": [],
   "source": [
    "# Generate a collection of OCSF events from mixed vendor spans\n",
    "\n",
    "all_spans = [\n",
    "    # LangChain spans\n",
    "    (\"ChatOpenAI\", {\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4o\",\n",
    "                    \"llm.token_count.prompt\": 200, \"llm.token_count.completion\": 150}),\n",
    "    (\"ChatAnthropic\", {\"ls_provider\": \"anthropic\", \"ls_model_name\": \"claude-sonnet-4-5-20250929\",\n",
    "                       \"llm.token_count.prompt\": 500, \"llm.token_count.completion\": 300}),\n",
    "    (\"AgentExecutor\", {\"langchain.agent.name\": \"qa-agent\"}),\n",
    "    (\"VectorStoreRetriever\", {\"langchain.retriever.name\": \"chroma-kb\", \"langchain.retriever.k\": 5}),\n",
    "    # CrewAI spans\n",
    "    (\"Crew Execution\", {\"crewai.agent.role\": \"analyst\", \"crewai.crew.name\": \"data-team\"}),\n",
    "    (\"LLM Call gpt-4o\", {\"crewai.llm.model\": \"gpt-4o\", \"crewai.llm.input_tokens\": 600}),\n",
    "    (\"Tool Execution calculator\", {\"crewai.tool.name\": \"calculator\", \"crewai.tool.duration_ms\": 12.5}),\n",
    "    (\"Task Delegation\", {\"crewai.delegation.from_agent\": \"lead\", \"crewai.delegation.to_agent\": \"analyst\"}),\n",
    "]\n",
    "\n",
    "print(f\"{'Span Name':<30s} {'Vendor':<12s} {'Event Type':<14s} {'OCSF':>6s}\")\n",
    "print(f\"{'-'*30} {'-'*12} {'-'*14} {'-'*6}\")\n",
    "\n",
    "ocsf_events = []\n",
    "for name, attrs in all_spans:\n",
    "    span = make_span(name, attrs)\n",
    "    result = vendor_mapper.normalize_span(span)\n",
    "    if result:\n",
    "        v, et, aa = result\n",
    "        uid = vendor_mapper.get_ocsf_class_uid(v, et) or \"?\"\n",
    "        print(f\"{name:<30s} {v:<12s} {et:<14s} {uid:>6}\")\n",
    "\n",
    "        # Map to OCSF through the full pipeline\n",
    "        norm_span = make_span(f\"{et} {name}\", aa)\n",
    "        ocsf_ev = ocsf_mapper.map_span(norm_span)\n",
    "        if ocsf_ev:\n",
    "            enriched = compliance_mapper.enrich_event(ocsf_ev, et.replace(\"inference\", \"model_inference\"))\n",
    "            ocsf_events.append(enriched)\n",
    "\n",
    "print(f\"\\nTotal OCSF events generated: {len(ocsf_events)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-jsonl"
   },
   "outputs": [],
   "source": [
    "# Export events as JSONL (the format used by OCSF Exporter)\n",
    "import io\n",
    "\n",
    "jsonl_buffer = io.StringIO()\n",
    "for ev in ocsf_events:\n",
    "    line = json.dumps(ev.model_dump(exclude_none=True), default=str)\n",
    "    jsonl_buffer.write(line + \"\\n\")\n",
    "\n",
    "jsonl_content = jsonl_buffer.getvalue()\n",
    "\n",
    "print(\"OCSF JSONL Export\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Events:    {len(ocsf_events)}\")\n",
    "print(f\"  Size:      {len(jsonl_content):,} bytes\")\n",
    "print(f\"  Format:    JSONL (one OCSF event per line)\")\n",
    "print(f\"\\nFirst event (preview):\")\n",
    "first_event = json.loads(jsonl_content.split(\"\\n\")[0])\n",
    "preview_keys = {\"class_uid\", \"type_uid\", \"activity_id\", \"category_uid\",\n",
    "                \"severity_id\", \"status_id\", \"message\", \"time\"}\n",
    "preview = {k: v for k, v in first_event.items() if k in preview_keys}\n",
    "pp(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-stats"
   },
   "outputs": [],
   "source": [
    "# Event statistics\n",
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter()\n",
    "vendor_counts = Counter()\n",
    "\n",
    "for name, attrs in all_spans:\n",
    "    span = make_span(name, attrs)\n",
    "    result = vendor_mapper.normalize_span(span)\n",
    "    if result:\n",
    "        v, et, _ = result\n",
    "        uid = vendor_mapper.get_ocsf_class_uid(v, et)\n",
    "        class_name = class_map.get(uid, (f\"Class {uid}\",))[0] if uid else \"Unknown\"\n",
    "        class_counts[class_name] += 1\n",
    "        vendor_counts[v] += 1\n",
    "\n",
    "print(\"Event Distribution by OCSF Class\")\n",
    "print(\"=\" * 50)\n",
    "for cls, count in class_counts.most_common():\n",
    "    bar = '#' * (count * 5)\n",
    "    print(f\"  {cls:<25s} {bar} {count}\")\n",
    "\n",
    "print(f\"\\nEvent Distribution by Vendor\")\n",
    "print(\"=\" * 50)\n",
    "for vendor, count in vendor_counts.most_common():\n",
    "    bar = '#' * (count * 5)\n",
    "    print(f\"  {vendor:<12s} {bar} {count}\")\n",
    "\n",
    "print(f\"\\n  Total spans processed: {sum(vendor_counts.values())}\")\n",
    "print(f\"  Unique OCSF classes:   {len(class_counts)}\")\n",
    "print(f\"  Unique vendors:        {len(vendor_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated the full AITF pipeline:\n",
    "\n",
    "| Step | Component | What it Does |\n",
    "|------|-----------|-------------|\n",
    "| 1 | **VendorMapper** | Normalizes LangChain/CrewAI/custom telemetry to AITF conventions |\n",
    "| 2 | **OCSFMapper** | Converts OTel spans to OCSF Category 7 events (7001-7008) |\n",
    "| 3 | **ComplianceMapper** | Enriches events with controls from 8 regulatory frameworks |\n",
    "| 4 | **AgenticLogInstrumentor** | Structured security-context log entries per Table 10.1 |\n",
    "| 5 | **AIBOMGenerator** | AI Bill of Materials in AITF/CycloneDX/SPDX formats |\n",
    "| 6 | **Exporters** | OCSF JSONL, Immutable Audit Logs, CEF Syslog to SIEM |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Production deployment**: See `docs/deployment-guide.md` for 10 complete deployment examples\n",
    "- **Custom vendor mapping**: Create a JSON file for your agentic framework\n",
    "- **SIEM integration**: Use the CEF Syslog exporter for Splunk/QRadar/ArcSight\n",
    "- **Detection rules**: See `examples/detection-rules/` for Sigma and Splunk queries\n",
    "\n",
    "---\n",
    "\n",
    "*AITF — Security-first telemetry for AI systems*"
   ]
  }
 ]
}
