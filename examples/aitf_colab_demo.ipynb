{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# AITF — AI Telemetry Framework\n",
    "\n",
    "## Interactive Demo on Google Colab\n",
    "\n",
    "**AITF** is a security-first telemetry framework for AI systems built on [OpenTelemetry](https://opentelemetry.io/) and [OCSF](https://ocsf.io/). It provides:\n",
    "\n",
    "| Capability | Description |\n",
    "|---|---|\n",
    "| **OCSF Category 7** | 8 AI event classes (7001–7008) for SIEM/XDR integration |\n",
    "| **12 Instrumentors** | LLM, Agent, MCP, RAG, Skills, ModelOps, Identity, and more |\n",
    "| **3 Exporters** | OCSF JSON, Immutable Audit Logs, CEF Syslog |\n",
    "| **4 Security Processors** | OWASP LLM Top 10, PII Redaction, Cost Tracking, Memory Monitoring |\n",
    "| **Vendor Mapping** | Declarative JSON mappings for LangChain, CrewAI, and custom frameworks |\n",
    "| **8 Compliance Frameworks** | NIST AI RMF, EU AI Act, MITRE ATLAS, ISO 42001, SOC2, GDPR, CCPA, CSA AICM |\n",
    "| **AI-BOM** | AI Bill of Materials generation in AITF, CycloneDX, and SPDX formats |\n",
    "\n",
    "This notebook walks through each capability interactively.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toc"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup & Installation](#setup)\n",
    "2. [OCSF Schema Explorer](#schema)\n",
    "3. [LLM Inference Tracing](#llm)\n",
    "4. [Agent Session Tracing](#agent)\n",
    "5. [Vendor Mapping — LangChain & CrewAI](#vendor)\n",
    "6. [Compliance Framework Mapping](#compliance)\n",
    "7. [Agentic Log Entries](#agentic-log)\n",
    "8. [AI-BOM Generation](#aibom)\n",
    "9. [Full Pipeline — End to End](#pipeline)\n",
    "10. [Export & Visualization](#viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 1. Setup & Installation <a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install AITF and dependencies\n",
    "# On Colab, this installs from the repo; locally you can use: pip install aitf\n",
    "import subprocess, sys\n",
    "\n",
    "# Clone the repo (Colab) or use local install\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab — installing from GitHub...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "                           \"opentelemetry-api\", \"opentelemetry-sdk\", \"pydantic>=2.0\"])\n",
    "    subprocess.check_call([\"git\", \"clone\", \"-q\", \"https://github.com/girdav01/AITF.git\", \"/content/AITF\"])\n",
    "    sys.path.insert(0, \"/content/AITF/sdk/python/src\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally.\")\n",
    "\n",
    "# Verify imports\n",
    "import aitf\n",
    "print(f\"\\nAITF version: {aitf.__version__}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "common-imports"
   },
   "outputs": [],
   "source": [
    "# Common imports used throughout the notebook\n",
    "import json\n",
    "from unittest.mock import MagicMock\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
    "\n",
    "# Pretty-print helper\n",
    "def pp(obj, title=None):\n",
    "    \"\"\"Pretty-print a dict or Pydantic model.\"\"\"\n",
    "    if title:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  {title}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    if hasattr(obj, 'model_dump'):\n",
    "        obj = obj.model_dump(exclude_none=True)\n",
    "    print(json.dumps(obj, indent=2, default=str))\n",
    "\n",
    "# Mock span helper (simulates what OpenTelemetry produces)\n",
    "def make_span(name, attributes=None):\n",
    "    \"\"\"Create a mock ReadableSpan for demonstration.\"\"\"\n",
    "    span = MagicMock()\n",
    "    span.name = name\n",
    "    span.attributes = attributes or {}\n",
    "    span.start_time = int(datetime.now(timezone.utc).timestamp() * 1e9)\n",
    "    return span\n",
    "\n",
    "print(\"Common imports loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "schema-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 2. OCSF Schema Explorer <a id=\"schema\"></a>\n",
    "\n",
    "AITF defines **Category 7: AI System Activity** in the OCSF schema with eight event classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "schema-explore"
   },
   "outputs": [],
   "source": [
    "from aitf.ocsf.schema import (\n",
    "    AIClassUID, AIBaseEvent, AIModelInfo, AITokenUsage,\n",
    "    AILatencyMetrics, AICostInfo, OCSFMetadata, OCSFSeverity,\n",
    "    ComplianceMetadata, AISecurityFinding,\n",
    ")\n",
    "from aitf.ocsf.event_classes import (\n",
    "    AIModelInferenceEvent, AIAgentActivityEvent, AIToolExecutionEvent,\n",
    "    AIDataRetrievalEvent, AISecurityFindingEvent, AISupplyChainEvent,\n",
    "    AIGovernanceEvent, AIIdentityEvent,\n",
    ")\n",
    "\n",
    "# Display all 8 OCSF Category 7 class UIDs\n",
    "print(\"OCSF Category 7 — AI System Activity\")\n",
    "print(\"=\" * 50)\n",
    "class_map = {\n",
    "    7001: (\"AI Model Inference\", AIModelInferenceEvent),\n",
    "    7002: (\"AI Agent Activity\", AIAgentActivityEvent),\n",
    "    7003: (\"AI Tool Execution\", AIToolExecutionEvent),\n",
    "    7004: (\"AI Data Retrieval\", AIDataRetrievalEvent),\n",
    "    7005: (\"AI Security Finding\", AISecurityFindingEvent),\n",
    "    7006: (\"AI Supply Chain\", AISupplyChainEvent),\n",
    "    7007: (\"AI Governance\", AIGovernanceEvent),\n",
    "    7008: (\"AI Identity\", AIIdentityEvent),\n",
    "}\n",
    "for uid, (name, cls) in class_map.items():\n",
    "    fields = [f for f in cls.model_fields if f not in AIBaseEvent.model_fields]\n",
    "    print(f\"\\n  {uid}: {name}\")\n",
    "    print(f\"         Fields: {', '.join(fields[:6])}{'...' if len(fields) > 6 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "schema-event-example"
   },
   "outputs": [],
   "source": [
    "# Create an OCSF event directly from Pydantic models\n",
    "event = AIModelInferenceEvent(\n",
    "    activity_id=1,  # chat\n",
    "    model=AIModelInfo(\n",
    "        model_id=\"claude-sonnet-4-5-20250929\",\n",
    "        provider=\"anthropic\",\n",
    "        type=\"llm\",\n",
    "    ),\n",
    "    token_usage=AITokenUsage(input_tokens=500, output_tokens=200),\n",
    "    latency=AILatencyMetrics(total_ms=1250.0, tokens_per_second=160.0),\n",
    "    cost=AICostInfo(input_cost_usd=0.0015, output_cost_usd=0.003, total_cost_usd=0.0045),\n",
    "    finish_reason=\"end_turn\",\n",
    "    streaming=True,\n",
    "    message=\"chat claude-sonnet-4-5-20250929\",\n",
    ")\n",
    "\n",
    "pp(event, \"OCSF 7001: AI Model Inference Event\")\n",
    "\n",
    "print(f\"\\n  class_uid:  {event.class_uid}\")\n",
    "print(f\"  type_uid:   {event.type_uid}  (class_uid * 100 + activity_id)\")\n",
    "print(f\"  category:   {event.category_uid}  (AI System Activity)\")\n",
    "print(f\"  tokens:     {event.token_usage.total_tokens}  ({event.token_usage.input_tokens} in + {event.token_usage.output_tokens} out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llm-header"
   },
   "source": "---\n\n## 3. LLM Inference Tracing <a id=\"llm\"></a>\n\nTrace LLM calls with the `OCSFMapper` — it converts OpenTelemetry spans to OCSF events.\n\n**Scenario:** A customer-support chatbot answers user questions.  Each LLM call\n(chat completion, embedding) produces a span that AITF maps to OCSF 7001.\n\n```python\n# What your chatbot code looks like (simplified):\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are the Acme support assistant.\"},\n    {\"role\": \"user\",   \"content\": \"How do I reset my password?\"},\n]\nresponse = openai.chat.completions.create(model=\"gpt-4o\", messages=messages)\n#                                          ↑ AITF captures this call automatically\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llm-mapper"
   },
   "outputs": [],
   "source": "from aitf.ocsf.mapper import OCSFMapper\n\nmapper = OCSFMapper()\n\n# ── Scenario: Customer asks \"How do I reset my password?\" ──\n# The chatbot sends the conversation to GPT-4o and gets a response.\n# AITF captures the span with all attributes:\n\nchat_span = make_span(\"chat gpt-4o\", {\n    # OpenTelemetry GenAI semantic conventions (what your app emits)\n    \"gen_ai.system\": \"openai\",\n    \"gen_ai.request.model\": \"gpt-4o\",\n    \"gen_ai.operation.name\": \"chat\",\n    \"gen_ai.request.temperature\": 0.4,\n    \"gen_ai.request.max_tokens\": 1024,\n    \"gen_ai.usage.input_tokens\": 350,   # system prompt + user question\n    \"gen_ai.usage.output_tokens\": 180,  # \"To reset your password, visit...\"\n    \"gen_ai.response.finish_reasons\": [\"stop\"],\n    # AITF-enriched attributes (added by processors)\n    \"aitf.latency.total_ms\": 920.5,\n    \"aitf.latency.tokens_per_second\": 195.6,\n    \"aitf.cost.total_cost\": 0.00265,\n    \"aitf.cost.input_cost\": 0.000875,\n    \"aitf.cost.output_cost\": 0.0018,\n})\n\nevent = mapper.map_span(chat_span)\npp(event, \"Customer Support Chat → OCSF 7001\")\n\n# ── Scenario: Embed the question for RAG retrieval ──\n# Before answering, the chatbot embeds the question to search the knowledge base.\n\nembed_span = make_span(\"embeddings text-embedding-3-small\", {\n    \"gen_ai.system\": \"openai\",\n    \"gen_ai.request.model\": \"text-embedding-3-small\",\n    \"gen_ai.operation.name\": \"embeddings\",\n    \"gen_ai.usage.input_tokens\": 42,  # \"How do I reset my password?\"\n})\n\nevent2 = mapper.map_span(embed_span)\nprint(f\"\\nEmbedding for KB search:  class_uid={event2.class_uid}, \"\n      f\"activity_id={event2.activity_id}, model_type={event2.model.type}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agent-header"
   },
   "source": "---\n\n## 4. Agent Session Tracing <a id=\"agent\"></a>\n\nMap agent lifecycle spans (session start, step execute, delegation, memory access) to OCSF 7002.\n\n**Scenario:** A travel-booking agent plans a trip, searches for flights, reasons\nabout the best option, books it, and stores the confirmation in memory.  Then a\nmulti-agent team delegates research and writing tasks.\n\n```python\n# What your agent code looks like (simplified):\nagent = TravelAgent(model=\"gpt-4o\", tools=[search_flights, book_flight])\nresult = agent.run(\"Book me a nonstop SFO→JFK flight on March 15\")\n#                   ↑ AITF traces: planning → tool_use → reasoning → booking\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agent-mapper"
   },
   "outputs": [],
   "source": "# ── Scenario: Travel agent plans approach and searches for flights ──\n# The agent thinks: \"User wants a nonstop SFO→JFK flight.  Let me\n# fetch their preferences, search flights, and pick the best one.\"\n\nagent_span = make_span(\"agent.step.planning\", {\n    \"aitf.agent.name\": \"travel-booking-agent\",\n    \"aitf.agent.id\": \"agent-travel-001\",\n    \"aitf.agent.session_id\": \"sess-abc123\",\n    \"aitf.agent.type\": \"autonomous\",\n    \"aitf.agent.framework\": \"custom\",\n    \"aitf.agent.step.type\": \"planning\",\n    \"aitf.agent.step.index\": 1,\n    \"aitf.agent.step.thought\": (\n        \"User wants nonstop SFO→JFK on March 15.  Steps: \"\n        \"1) fetch preferences, 2) search flights, 3) filter nonstop + preferred airlines, \"\n        \"4) book the cheapest.\"\n    ),\n    \"aitf.agent.step.action\": \"call_tool:flight-search\",\n})\n\nevent = mapper.map_span(agent_span)\npp(event, \"Travel Agent Planning Step → OCSF 7002\")\n\n# ── Scenario: Manager delegates to researcher in a multi-agent team ──\n# CrewAI-style: the manager assigns a research task to a specialist agent.\n\ndelegation_span = make_span(\"agent.delegation\", {\n    \"aitf.agent.name\": \"manager\",\n    \"aitf.agent.id\": \"agent-mgr\",\n    \"aitf.agent.session_id\": \"sess-abc123\",\n    \"aitf.agent.delegation.target_agent\": \"researcher\",\n    # In a real app: manager.delegate(to=\"researcher\", task=\"Research AI supply-chain risks\")\n})\n\nevent2 = mapper.map_span(delegation_span)\nprint(f\"\\nDelegation: activity_id={event2.activity_id} (4=Delegation)\")\nprint(f\"From: {event2.agent_name} → To: {event2.delegation_target}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tool-mapper"
   },
   "outputs": [],
   "source": "# ── Scenario: Agent calls an MCP tool to search the knowledge base ──\n# The support agent invokes the \"search_knowledge_base\" tool via MCP\n# to find relevant articles before answering the customer's question.\n\ntool_span = make_span(\"mcp.tool.search_knowledge_base\", {\n    \"aitf.mcp.tool.name\": \"search_knowledge_base\",\n    \"aitf.mcp.tool.server\": \"kb-server\",\n    \"aitf.mcp.server.transport\": \"stdio\",\n    \"aitf.mcp.tool.input\": '{\"query\": \"How do I reset my password?\"}',\n    \"aitf.mcp.tool.output\": '[{\"title\": \"Password Reset Guide\", \"score\": 0.95}, '\n                            '{\"title\": \"MFA Setup\", \"score\": 0.82}]',\n    \"aitf.mcp.tool.duration_ms\": 245.3,\n    \"aitf.mcp.tool.is_error\": False,\n    \"aitf.mcp.tool.approval_required\": True,\n    \"aitf.mcp.tool.approved\": True,\n})\n\nevent = mapper.map_span(tool_span)\npp(event, \"MCP Tool: KB Search → OCSF 7003\")\n\n# ── Scenario: RAG retrieval — vector search for similar support tickets ──\n# The chatbot retrieves past tickets to provide context-aware answers.\n\nrag_span = make_span(\"rag.retrieve\", {\n    \"aitf.rag.retrieve.database\": \"pinecone\",\n    \"aitf.rag.query\": \"password reset not working after MFA change\",\n    \"aitf.rag.retrieve.top_k\": 10,\n    \"aitf.rag.retrieve.results_count\": 8,\n    \"aitf.rag.retrieve.min_score\": 0.72,\n    \"aitf.rag.retrieve.max_score\": 0.98,\n    \"aitf.rag.pipeline.name\": \"support-ticket-qa\",\n    \"aitf.rag.pipeline.stage\": \"retrieve\",\n    \"aitf.rag.query.embedding_model\": \"text-embedding-3-large\",\n})\n\nevent2 = mapper.map_span(rag_span)\npp(event2, \"RAG: Ticket Retrieval → OCSF 7004\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vendor-header"
   },
   "source": "---\n\n## 5. Vendor Mapping — LangChain & CrewAI <a id=\"vendor\"></a>\n\nVendors supply **JSON mapping files** that translate their native telemetry to AITF conventions. No custom code needed — the `VendorMapper` loads the JSON and handles everything.\n\n**Scenario:** Your app uses LangChain for a customer-support chatbot (ChatOpenAI + VectorStoreRetriever) and CrewAI for a security-audit crew (agents + tools + delegation).  Each framework emits its own attributes — the VendorMapper normalizes them all.\n\n```\nLangChain ChatOpenAI  ─┐\nLangChain Retriever   ─┤  VendorMapper  ──>  OCSFMapper  ──>  SIEM\nCrewAI Agent          ─┤  (JSON-driven)      (standard)       (OCSF)\nCrewAI Tool           ─┘\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vendor-setup"
   },
   "outputs": [],
   "source": [
    "from aitf.ocsf.vendor_mapper import VendorMapper\n",
    "\n",
    "vendor_mapper = VendorMapper()\n",
    "\n",
    "print(\"Loaded Vendor Mappings\")\n",
    "print(\"=\" * 60)\n",
    "for info in vendor_mapper.list_supported_vendors():\n",
    "    print(f\"\\n  Vendor:      {info['vendor']}\")\n",
    "    print(f\"  Version:     {info['version']}\")\n",
    "    print(f\"  Event Types: {info['event_types']}\")\n",
    "    print(f\"  Description: {info['description'][:70]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vendor-langchain"
   },
   "outputs": [],
   "source": "# ── Scenario: LangChain customer-support chatbot ──\n# The chatbot uses ChatOpenAI for generation and a VectorStoreRetriever\n# for RAG against the support knowledge base.\n\n# Step 1: LangChain ChatOpenAI answers \"How do I reset my password?\"\nlc_inference = make_span(\"ChatOpenAI\", {\n    # LangChain-native attributes (what LangSmith would emit)\n    \"ls_provider\": \"openai\",\n    \"ls_model_name\": \"gpt-4o\",\n    \"ls_temperature\": 0.4,\n    \"llm.token_count.prompt\": 380,   # system prompt + KB context + user question\n    \"llm.token_count.completion\": 120,  # \"Visit sso.acme.corp/reset...\"\n    \"llm.token_count.total\": 500,\n    \"langchain.run.response_id\": \"chatcmpl-abc123\",\n    \"langchain.run.finish_reason\": \"stop\",\n})\n\nresult = vendor_mapper.normalize_span(lc_inference)\nvendor, event_type, aitf_attrs = result\n\nprint(\"LangChain ChatOpenAI (Support Bot) → AITF\")\nprint(\"=\" * 60)\nprint(f\"  Detected Vendor: {vendor}\")\nprint(f\"  Event Type:      {event_type}\")\nprint(f\"  OCSF Class UID:  {vendor_mapper.get_ocsf_class_uid(vendor, event_type)}\")\nprint(f\"\\n  Attribute Translation (LangChain → AITF):\")\nprint(f\"    ls_provider           → gen_ai.system         = {aitf_attrs.get('gen_ai.system')}\")\nprint(f\"    ls_model_name         → gen_ai.request.model  = {aitf_attrs.get('gen_ai.request.model')}\")\nprint(f\"    ls_temperature        → gen_ai.request.temp   = {aitf_attrs.get('gen_ai.request.temperature')}\")\nprint(f\"    llm.token_count.*     → gen_ai.usage.*        = {aitf_attrs.get('gen_ai.usage.input_tokens')} in / {aitf_attrs.get('gen_ai.usage.output_tokens')} out\")\n\n# Step 2: LangChain VectorStoreRetriever searches the support KB\nlc_rag = make_span(\"VectorStoreRetriever\", {\n    \"langchain.retriever.name\": \"support-kb-pinecone\",\n    \"langchain.retriever.type\": \"pinecone\",\n    \"langchain.retriever.k\": 8,\n    \"langchain.retriever.query\": \"How do I reset my password?\",\n    \"langchain.retriever.documents\": 6,\n    \"retriever.embeddings.model\": \"text-embedding-3-small\",\n})\n\nresult = vendor_mapper.normalize_span(lc_rag)\nprint(f\"\\n\\nLangChain Retriever (KB Search) → {result[1]} (OCSF {vendor_mapper.get_ocsf_class_uid(*result[:2])})\")\nprint(\"  Translated attributes:\")\nfor k, v in sorted(result[2].items()):\n    print(f\"    {k}: {v}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vendor-crewai"
   },
   "outputs": [],
   "source": "# ── Scenario: CrewAI security audit crew ──\n# A manager agent coordinates a vuln-scanner and report-writer.\n# CrewAI emits crewai.* attributes that VendorMapper normalizes.\n\n# Agent execution: security-researcher analyzes threat intel\ncrew_agent = make_span(\"Agent Execution\", {\n    \"crewai.agent.role\": \"security-researcher\",\n    \"crewai.agent.goal\": \"Analyze threat intelligence reports for CVE-2024-46946\",\n    \"crewai.agent.backstory\": \"15 years in cybersecurity, specializing in supply-chain attacks\",\n    \"crewai.agent.id\": \"agent-sec-001\",\n    \"crewai.agent.llm\": \"claude-sonnet-4-5-20250929\",\n    \"crewai.agent.tools\": \"web_search,cve_lookup,code_scan\",\n    \"crewai.crew.name\": \"security-audit-crew\",\n    \"crewai.crew.process\": \"hierarchical\",\n})\n\nresult = vendor_mapper.normalize_span(crew_agent)\nvendor, event_type, aitf_attrs = result\n\nprint(\"CrewAI Security Researcher → AITF\")\nprint(\"=\" * 60)\nprint(f\"  Vendor: {vendor}, Event: {event_type}, OCSF: {vendor_mapper.get_ocsf_class_uid(vendor, event_type)}\")\nprint(f\"\\n  CrewAI → AITF translations:\")\nprint(f\"    crewai.agent.role    → aitf.agent.name          = {aitf_attrs.get('aitf.agent.name')}\")\nprint(f\"    crewai.crew.name     → aitf.agent.team.name     = {aitf_attrs.get('aitf.agent.team.name')}\")\nprint(f\"    crewai.crew.process  → aitf.agent.team.topology = {aitf_attrs.get('aitf.agent.team.topology')}\")\nprint(f\"    (default)            → aitf.agent.framework     = {aitf_attrs.get('aitf.agent.framework')}\")\n\n# Task delegation: manager assigns report writing to specialist\ncrew_delegation = make_span(\"Task Delegation\", {\n    \"crewai.delegation.from_agent\": \"security-manager\",\n    \"crewai.delegation.to_agent\": \"report-writer\",\n    \"crewai.delegation.task\": \"Write executive summary of CVE-2024-46946 impact\",\n    \"crewai.delegation.reason\": \"Requires professional report writing skills\",\n    \"crewai.delegation.strategy\": \"capability\",\n})\n\nresult = vendor_mapper.normalize_span(crew_delegation)\nprint(f\"\\n\\nCrewAI Delegation → {result[1]} (OCSF {vendor_mapper.get_ocsf_class_uid(*result[:2])})\")\nfor k, v in sorted(result[2].items()):\n    print(f\"    {k}: {v}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vendor-custom"
   },
   "outputs": [],
   "source": [
    "# --- Load a custom vendor mapping at runtime ---\n",
    "\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "autogen_mapping = {\n",
    "    \"vendor\": \"autogen\",\n",
    "    \"version\": \"0.4\",\n",
    "    \"description\": \"Maps Microsoft AutoGen telemetry to AITF conventions\",\n",
    "    \"homepage\": \"https://microsoft.github.io/autogen/\",\n",
    "    \"span_name_patterns\": {\n",
    "        \"inference\": [\"^AutoGen\\\\.LLM\", \"^AutoGen\\\\.ChatCompletion\"],\n",
    "        \"agent\": [\"^AutoGen\\\\.Agent\", \"^AutoGen\\\\.GroupChat\"],\n",
    "    },\n",
    "    \"attribute_mappings\": {\n",
    "        \"inference\": {\n",
    "            \"vendor_to_aitf\": {\n",
    "                \"autogen.llm.model\": \"gen_ai.request.model\",\n",
    "                \"autogen.llm.provider\": \"gen_ai.system\",\n",
    "                \"autogen.llm.input_tokens\": \"gen_ai.usage.input_tokens\",\n",
    "                \"autogen.llm.output_tokens\": \"gen_ai.usage.output_tokens\",\n",
    "            },\n",
    "            \"ocsf_class_uid\": 7001,\n",
    "            \"ocsf_activity_id_map\": {\"chat\": 1, \"default\": 1},\n",
    "            \"defaults\": {\"gen_ai.operation.name\": \"chat\"},\n",
    "        },\n",
    "        \"agent\": {\n",
    "            \"vendor_to_aitf\": {\n",
    "                \"autogen.agent.name\": \"aitf.agent.name\",\n",
    "                \"autogen.agent.type\": \"aitf.agent.type\",\n",
    "                \"autogen.group.name\": \"aitf.agent.team.name\",\n",
    "            },\n",
    "            \"ocsf_class_uid\": 7002,\n",
    "            \"ocsf_activity_id_map\": {\"default\": 3},\n",
    "            \"defaults\": {\"aitf.agent.framework\": \"autogen\"},\n",
    "        },\n",
    "    },\n",
    "    \"provider_detection\": {\n",
    "        \"attribute_keys\": [\"autogen.llm.provider\"],\n",
    "        \"model_prefix_to_provider\": {\"gpt-\": \"openai\", \"claude-\": \"anthropic\"},\n",
    "    },\n",
    "    \"severity_mapping\": {},\n",
    "    \"metadata\": {\n",
    "        \"ocsf_product\": {\"name\": \"AutoGen\", \"vendor_name\": \"Microsoft\", \"version\": \"0.4\"},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Write to temp file and load\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".json\", delete=False) as f:\n",
    "    json.dump(autogen_mapping, f)\n",
    "    tmp_path = f.name\n",
    "\n",
    "vendor_mapper.load_file(tmp_path)\n",
    "\n",
    "print(\"Custom Vendor Mapping Loaded\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Total vendors: {len(vendor_mapper.vendors)}\")\n",
    "print(f\"  Vendors: {', '.join(vendor_mapper.vendors)}\")\n",
    "\n",
    "# Test AutoGen span\n",
    "autogen_span = make_span(\"AutoGen.Agent.execute\", {\n",
    "    \"autogen.agent.name\": \"code-reviewer\",\n",
    "    \"autogen.agent.type\": \"assistant\",\n",
    "    \"autogen.group.name\": \"dev-team\",\n",
    "})\n",
    "\n",
    "result = vendor_mapper.normalize_span(autogen_span)\n",
    "print(f\"\\n  AutoGen span detected: {result[0]}/{result[1]}\")\n",
    "print(f\"  Translated attributes:\")\n",
    "for k, v in sorted(result[2].items()):\n",
    "    print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compliance-header"
   },
   "source": [
    "---\n",
    "\n",
    "## 6. Compliance Framework Mapping <a id=\"compliance\"></a>\n",
    "\n",
    "AITF maps every AI event to controls from **8 regulatory frameworks** automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compliance-mapper"
   },
   "outputs": [],
   "source": [
    "from aitf.ocsf.compliance_mapper import ComplianceMapper\n",
    "\n",
    "compliance_mapper = ComplianceMapper()\n",
    "\n",
    "# Map model_inference to all 8 frameworks\n",
    "compliance = compliance_mapper.map_event(\"model_inference\")\n",
    "\n",
    "print(\"Compliance Mapping: model_inference\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "frameworks = [\n",
    "    (\"NIST AI RMF\", compliance.nist_ai_rmf),\n",
    "    (\"MITRE ATLAS\", compliance.mitre_atlas),\n",
    "    (\"ISO 42001\", compliance.iso_42001),\n",
    "    (\"EU AI Act\", compliance.eu_ai_act),\n",
    "    (\"SOC 2\", compliance.soc2),\n",
    "    (\"GDPR\", compliance.gdpr),\n",
    "    (\"CCPA\", compliance.ccpa),\n",
    "    (\"CSA AICM\", compliance.csa_aicm),\n",
    "]\n",
    "\n",
    "for name, data in frameworks:\n",
    "    if data:\n",
    "        # Get the primary control list\n",
    "        controls = data.get(\"controls\") or data.get(\"techniques\") or data.get(\"articles\") or data.get(\"sections\") or []\n",
    "        display = controls[:5]\n",
    "        suffix = f\" (+{len(controls)-5} more)\" if len(controls) > 5 else \"\"\n",
    "        print(f\"  {name:15s} {', '.join(str(c) for c in display)}{suffix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compliance-matrix"
   },
   "outputs": [],
   "source": [
    "# Coverage matrix — which frameworks apply to each event type\n",
    "matrix = compliance_mapper.get_coverage_matrix()\n",
    "\n",
    "print(\"Compliance Coverage Matrix\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "header_fw = [\"nist\", \"atlas\", \"iso\", \"eu_ai\", \"soc2\", \"gdpr\", \"ccpa\", \"aicm\"]\n",
    "fw_keys = [\"nist_ai_rmf\", \"mitre_atlas\", \"iso_42001\", \"eu_ai_act\", \"soc2\", \"gdpr\", \"ccpa\", \"csa_aicm\"]\n",
    "\n",
    "print(f\"  {'Event Type':22s} {' '.join(f'{h:>6s}' for h in header_fw)}  Total\")\n",
    "print(f\"  {'-'*22} {' '.join(['------'] * 8)}  -----\")\n",
    "\n",
    "for event_type, fw_map in matrix.items():\n",
    "    counts = []\n",
    "    total = 0\n",
    "    for fk in fw_keys:\n",
    "        n = len(fw_map.get(fk, []))\n",
    "        counts.append(n)\n",
    "        total += n\n",
    "    print(f\"  {event_type:22s} {' '.join(f'{c:6d}' for c in counts)}  {total:5d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compliance-enrich"
   },
   "outputs": [],
   "source": [
    "# Enrich an OCSF event with compliance metadata\n",
    "event = AIModelInferenceEvent(\n",
    "    activity_id=1,\n",
    "    model=AIModelInfo(model_id=\"gpt-4o\", provider=\"openai\"),\n",
    "    token_usage=AITokenUsage(input_tokens=100, output_tokens=50),\n",
    "    finish_reason=\"stop\",\n",
    ")\n",
    "\n",
    "enriched = compliance_mapper.enrich_event(event, \"model_inference\")\n",
    "\n",
    "print(\"Enriched OCSF Event (with compliance)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Event class: {enriched.class_uid} ({enriched.message or 'model_inference'})\")\n",
    "print(f\"  Has compliance: {enriched.compliance is not None}\")\n",
    "print(f\"  NIST controls: {enriched.compliance.nist_ai_rmf}\")\n",
    "print(f\"  EU AI Act:     {enriched.compliance.eu_ai_act}\")\n",
    "\n",
    "# Generate audit record\n",
    "audit = compliance_mapper.generate_audit_record(\n",
    "    event_type=\"model_inference\",\n",
    "    actor=\"analyst@example.com\",\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "pp(audit, \"Audit Record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agentic-log-header"
   },
   "source": "---\n\n## 7. Agentic Log Entries <a id=\"agentic-log\"></a>\n\nStructured log entries that capture security-relevant context for every AI agent action, based on the **Table 10.1 minimal fields** specification.\n\n**Scenario:** A DevOps incident-response agent handles a production alert for high CPU on the payments service.  It checks health, queries logs, runs EXPLAIN on a slow query, and applies a hotfix — each action logged with goal, tool, outcome, confidence, anomaly score, and policy evaluation.\n\n```python\n# What your incident-response agent does:\nhealth = k8s.check_health(\"payments-service\")       # CPU 94%, degraded\nlogs = datadog.query_logs(\"payments-service\", \"15m\") # QueryTimeout errors\nexplain = postgres.explain(slow_query)               # Seq Scan on 2.4M rows\npostgres.kill_slow_queries(min_duration=\"30s\")       # Fix: kill + add index\n# ↑ Every action is agentic-logged with policy evaluation\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agentic-log-demo"
   },
   "outputs": [],
   "source": "from aitf.instrumentation.agentic_log import AgenticLogInstrumentor\n\nprovider = TracerProvider()\nprovider.add_span_processor(SimpleSpanProcessor(ConsoleSpanExporter()))\ntrace.set_tracer_provider(provider)\n\nagentic_log = AgenticLogInstrumentor(tracer_provider=provider)\n\n# ── Scenario: DevOps agent checks service health ──\n# First action in an incident-response workflow.\nprint(\"Agentic Log: DevOps Incident Response\")\nprint(\"=\" * 60)\nprint(\"  ALERT: payments-service CPU at 94%\\n\")\n\nwith agentic_log.log_action(\n    agent_id=\"agent-devops-responder-prod-001\",\n    session_id=\"sess-inc-4421\",\n    event_id=\"e-health-check-001\",\n) as entry:\n    entry.set_goal_id(\"goal-resolve-payments-cpu-alert\")\n    entry.set_sub_task_id(\"task-check-health\")\n    entry.set_tool_used(\"k8s.health_check\")\n    entry.set_tool_parameters({\"service\": \"payments-service\", \"namespace\": \"production\"})\n    entry.set_outcome(\"SUCCESS\")\n    entry.set_confidence_score(0.95)\n    entry.set_anomaly_score(0.10)\n    entry.set_policy_evaluation({\n        \"policy\": \"read_only_monitoring\",\n        \"result\": \"PASS\",\n    })\n\nprint(f\"  Event ID:      {entry.event_id}\")\nprint(f\"  Timestamp:     {entry.timestamp}\")\nprint(f\"  Agent:         agent-devops-responder-prod-001\")\nprint(f\"  Goal:          goal-resolve-payments-cpu-alert\")\nprint(f\"  Tool:          k8s.health_check\")\nprint(f\"  Outcome:       SUCCESS\")\nprint(f\"  Confidence:    0.95\")\nprint(f\"  Anomaly:       0.10  (low = normal read-only operation)\")\nprint(f\"  Policy:        PASS  (read_only_monitoring)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agentic-log-anomaly"
   },
   "outputs": [],
   "source": "# ── Scenario: Agent tries a destructive action → DENIED by policy ──\n# The agent wants to DROP a cache table, but the policy engine blocks it.\n# High anomaly score (0.92) would trigger a SIEM alert.\n\nprint(\"Agentic Log: Blocked Destructive Action\")\nprint(\"=\" * 60)\nprint(\"  Agent attempts: DROP TABLE query_cache CASCADE\\n\")\n\nwith agentic_log.log_action(\n    agent_id=\"agent-devops-responder-prod-001\",\n    session_id=\"sess-inc-4421\",\n    goal_id=\"goal-resolve-payments-cpu-alert\",\n    sub_task_id=\"task-drop-cache-table\",\n    tool_used=\"postgres.drop_table\",\n    tool_parameters={\"table\": \"query_cache\", \"cascade\": True},\n) as entry:\n    entry.set_outcome(\"DENIED\")\n    entry.set_confidence_score(0.40)\n    entry.set_anomaly_score(0.92)\n    entry.set_policy_evaluation({\n        \"policy\": \"destructive_operations\",\n        \"result\": \"FAIL\",\n        \"reason\": \"DROP TABLE is permanently destructive — requires human approval\",\n        \"escalated_to\": \"oncall@acme.corp\",\n    })\n\nprint(f\"  Outcome:       DENIED\")\nprint(f\"  Confidence:    0.40  (agent was unsure this was the right fix)\")\nprint(f\"  Anomaly:       0.92  (HIGH — triggers SIEM alert)\")\nprint(f\"  Policy:        FAIL  (destructive_operations)\")\nprint(f\"  Escalation:    oncall@acme.corp\")\nprint(f\"\\n  In production, this generates an OCSF security finding event\")\nprint(f\"  and pages the on-call engineer for manual review.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aibom-header"
   },
   "source": "---\n\n## 8. AI-BOM Generation <a id=\"aibom\"></a>\n\nGenerate an **AI Bill of Materials** from telemetry — automatically discovers models, tools, and frameworks in use.\n\n**Scenario:** A fraud-detection platform uses Claude Sonnet for transaction scoring, GPT-4o for report generation, Pinecone for similar-case retrieval, and LangChain for agent orchestration.  The AI-BOM catalogs every AI component and flags known vulnerabilities (e.g., CVE-2024-46946 in LangChain)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aibom-demo"
   },
   "outputs": [],
   "source": "from aitf.generators.ai_bom import AIBOMGenerator\n\nbom = AIBOMGenerator(\n    system_name=\"fraud-detection-platform\",\n    system_version=\"4.2.0\",\n)\n\n# ── Register components discovered in the fraud-detection platform ──\n# In production, models and tools are auto-discovered from OTel spans.\n# Here we register them manually to show the AI-BOM structure.\n\n# Models used for transaction scoring and report generation\nbom.add_component(\"model\", \"claude-sonnet-4-5-20250929\", \"20250929\", provider=\"Anthropic\", license=\"Commercial\")\nbom.add_component(\"model\", \"gpt-4o\", \"2025-01-01\", provider=\"OpenAI\", license=\"Commercial\")\nbom.add_component(\"model\", \"text-embedding-3-large\", \"2024-01-25\", provider=\"OpenAI\", license=\"Commercial\")\n\n# Frameworks and infrastructure\nbom.add_component(\"framework\", \"langchain\", \"0.3.12\", provider=\"LangChain Inc.\", license=\"MIT\")\nbom.add_component(\"vector_store\", \"pinecone\", \"3.0.0\", provider=\"Pinecone\")\nbom.add_component(\"tool\", \"merchant-risk-mcp\", \"2.3.0\", provider=\"internal\")\n\n# Guardrails and prompt templates\nbom.add_component(\"guardrail\", \"pii-redaction-filter\", \"2.4\", provider=\"internal\",\n                   description=\"Redacts card numbers and SSNs before model input\")\nbom.add_component(\"prompt_template\", \"fraud-scoring-v3\", \"3.1\", provider=\"internal\",\n                   properties={\"category\": \"fraud_detection\", \"reviewed\": True})\n\n# Known vulnerabilities in dependencies\nbom.add_vulnerability(\"framework\", \"langchain\", \"CVE-2024-46946\",\n    severity=\"high\", description=\"Arbitrary code execution via YAML deserialization\")\nbom.add_vulnerability(\"framework\", \"langchain\", \"CVE-2024-28088\",\n    severity=\"medium\", description=\"SSRF in web retrieval chain\")\n\nprint(\"Fraud Detection Platform — AI-BOM Components\")\nprint(\"=\" * 60)\nsummary = bom.get_component_summary()\npp(summary)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aibom-formats"
   },
   "outputs": [],
   "source": "# Generate AI-BOM in multiple formats\ndoc = bom.generate(bom_id=\"bom-fraud-platform-2026-001\")\n\nprint(f\"AI-BOM: Fraud Detection Platform\")\nprint(f\"  ID:              {doc.bom_id}\")\nprint(f\"  System:          {doc.system_name} v{doc.system_version}\")\nprint(f\"  Components:      {doc.component_count}\")\nprint(f\"  Types:           {doc.component_types}\")\nprint(f\"  Vulnerabilities: {len(doc.vulnerabilities)}\")\n\n# CycloneDX — the format used by most vulnerability scanners\ncdx = doc.to_cyclonedx()\nprint(f\"\\nCycloneDX Export (for dependency scanners)\")\nprint(f\"  bomFormat:       {cdx['bomFormat']}\")\nprint(f\"  specVersion:     {cdx['specVersion']}\")\nprint(f\"  components:      {len(cdx['components'])}\")\nprint(f\"  vulnerabilities: {len(cdx.get('vulnerabilities', []))}\")\n\n# SPDX — the format used for license compliance\nspdx = doc.to_spdx()\nprint(f\"\\nSPDX Export (for license compliance)\")\nprint(f\"  spdxVersion:     {spdx['spdxVersion']}\")\nprint(f\"  packages:        {len(spdx['packages'])}\")\n\n# Show a sample component\nprint(f\"\\nSample Component (CycloneDX):\")\npp(cdx['components'][0])"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pipeline-header"
   },
   "source": "---\n\n## 9. Full Pipeline — End to End <a id=\"pipeline\"></a>\n\nDemonstrates the complete flow from framework-native telemetry to SIEM-ready events:\n\n```\nYour App Code (LangChain/CrewAI)\n    ↓ emits vendor-native spans\nVendorMapper (JSON-driven normalization)\n    ↓ AITF semantic conventions\nOCSFMapper (span → OCSF event)\n    ↓ OCSF Category 7 events\nComplianceMapper (regulatory enrichment)\n    ↓ NIST AI RMF + EU AI Act + ...\nSIEM / XDR (Splunk, QRadar, Sentinel)\n```\n\n**Scenario:** A LangChain `ChatAnthropic` span from the customer-support bot flows through the entire pipeline, emerging as a compliance-enriched OCSF event."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pipeline-demo"
   },
   "outputs": [],
   "source": [
    "from aitf.ocsf.vendor_mapper import VendorMapper\n",
    "from aitf.ocsf.mapper import OCSFMapper\n",
    "from aitf.ocsf.compliance_mapper import ComplianceMapper\n",
    "\n",
    "# Initialize the pipeline\n",
    "vendor_mapper = VendorMapper()\n",
    "ocsf_mapper = OCSFMapper()\n",
    "compliance_mapper = ComplianceMapper(frameworks=[\"nist_ai_rmf\", \"eu_ai_act\", \"csa_aicm\"])\n",
    "\n",
    "# Simulate a LangChain inference span with vendor-native attributes\n",
    "raw_span = make_span(\"ChatAnthropic\", {\n",
    "    \"ls_provider\": \"anthropic\",\n",
    "    \"ls_model_name\": \"claude-sonnet-4-5-20250929\",\n",
    "    \"ls_temperature\": 0.5,\n",
    "    \"llm.token_count.prompt\": 500,\n",
    "    \"llm.token_count.completion\": 300,\n",
    "    \"llm.token_count.total\": 800,\n",
    "})\n",
    "\n",
    "print(\"Full Pipeline Execution\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Step 1: Vendor normalization\n",
    "norm = vendor_mapper.normalize_span(raw_span)\n",
    "vendor, event_type, aitf_attrs = norm\n",
    "print(f\"\\n  Step 1 — Vendor Detection\")\n",
    "print(f\"    Vendor:     {vendor}\")\n",
    "print(f\"    Event Type: {event_type}\")\n",
    "print(f\"    Attributes: {len(aitf_attrs)} AITF keys\")\n",
    "\n",
    "# Step 2: Create a normalized span and map to OCSF\n",
    "normalized_span = make_span(f\"chat {aitf_attrs.get('gen_ai.request.model', 'unknown')}\", aitf_attrs)\n",
    "ocsf_event = ocsf_mapper.map_span(normalized_span)\n",
    "\n",
    "print(f\"\\n  Step 2 — OCSF Mapping\")\n",
    "print(f\"    Class UID:   {ocsf_event.class_uid}  (AI Model Inference)\")\n",
    "print(f\"    Type UID:    {ocsf_event.type_uid}\")\n",
    "print(f\"    Activity:    {ocsf_event.activity_id}  (chat)\")\n",
    "print(f\"    Model:       {ocsf_event.model.model_id}\")\n",
    "print(f\"    Provider:    {ocsf_event.model.provider}\")\n",
    "print(f\"    Tokens:      {ocsf_event.token_usage.total_tokens}\")\n",
    "\n",
    "# Step 3: Compliance enrichment\n",
    "enriched = compliance_mapper.enrich_event(ocsf_event, \"model_inference\")\n",
    "\n",
    "print(f\"\\n  Step 3 — Compliance Enrichment\")\n",
    "print(f\"    NIST AI RMF: {enriched.compliance.nist_ai_rmf['controls']}\")\n",
    "print(f\"    EU AI Act:   {enriched.compliance.eu_ai_act['articles']}\")\n",
    "csa = enriched.compliance.csa_aicm\n",
    "print(f\"    CSA AICM:    {len(csa['controls'])} controls across {csa['domains']}\")\n",
    "\n",
    "# Final serialized event\n",
    "final = enriched.model_dump(exclude_none=True)\n",
    "print(f\"\\n  Final OCSF event: {len(json.dumps(final))} bytes\")\n",
    "print(f\"  Top-level keys: {list(final.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pipeline-crewai"
   },
   "outputs": [],
   "source": "# ── Full pipeline with a CrewAI security audit crew ──\n# Simulates a real CrewAI workflow: manager coordinates vulnerability\n# scanning and report writing across multiple agents.\n\nspans = [\n    # Manager agent kicks off the security audit\n    (\"Crew Execution\", {\n        \"crewai.agent.role\": \"security-manager\",\n        \"crewai.agent.id\": \"agent-mgr-001\",\n        \"crewai.agent.goal\": \"Coordinate security audit of payments service\",\n        \"crewai.crew.name\": \"security-audit-crew\",\n        \"crewai.crew.process\": \"hierarchical\",\n    }),\n    # Claude Sonnet analyzes vulnerabilities\n    (\"LLM Call claude-sonnet-4-5-20250929\", {\n        \"crewai.llm.model\": \"claude-sonnet-4-5-20250929\",\n        \"crewai.llm.provider\": \"anthropic\",\n        \"crewai.llm.input_tokens\": 1500,\n        \"crewai.llm.output_tokens\": 600,\n        \"crewai.llm.response_time_ms\": 2800.0,\n    }),\n    # Tool: CVE lookup for langchain vulnerabilities\n    (\"Tool Execution cve_lookup\", {\n        \"crewai.tool.name\": \"cve_lookup\",\n        \"crewai.tool.input\": '{\"package\": \"langchain\", \"min_severity\": \"high\"}',\n        \"crewai.tool.output\": '[{\"id\": \"CVE-2024-46946\", \"severity\": \"high\"}]',\n        \"crewai.tool.agent\": \"vuln-scanner\",\n        \"crewai.tool.duration_ms\": 1850.0,\n    }),\n    # Manager delegates report writing\n    (\"Task Delegation\", {\n        \"crewai.delegation.from_agent\": \"security-manager\",\n        \"crewai.delegation.to_agent\": \"report-writer\",\n        \"crewai.delegation.task\": \"Write executive summary of security findings\",\n        \"crewai.delegation.reason\": \"Requires professional report writing skills\",\n    }),\n    # GPT-4o generates the executive report\n    (\"LLM Call gpt-4o\", {\n        \"crewai.llm.model\": \"gpt-4o\",\n        \"crewai.llm.provider\": \"openai\",\n        \"crewai.llm.input_tokens\": 2200,\n        \"crewai.llm.output_tokens\": 900,\n        \"crewai.llm.response_time_ms\": 3200.0,\n    }),\n]\n\nprint(\"CrewAI Security Audit → Full Pipeline\")\nprint(\"=\" * 70)\n\nevents_collected = []\nfor span_name, attrs in spans:\n    span = make_span(span_name, attrs)\n    result = vendor_mapper.normalize_span(span)\n    if result:\n        vendor, etype, aitf_a = result\n        class_uid = vendor_mapper.get_ocsf_class_uid(vendor, etype)\n        events_collected.append({\n            \"span\": span_name,\n            \"vendor\": vendor,\n            \"event_type\": etype,\n            \"ocsf_class\": class_uid,\n            \"aitf_keys\": len(aitf_a),\n        })\n        print(f\"\\n  {span_name}\")\n        print(f\"    → {vendor}/{etype} → OCSF {class_uid} | {len(aitf_a)} AITF attrs\")\n\nprint(f\"\\n  Total events: {len(events_collected)}\")\nprint(f\"  Event types: {set(e['event_type'] for e in events_collected)}\")\nprint(f\"  All events are compliance-enriched and SIEM-ready.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viz-header"
   },
   "source": "---\n\n## 10. Export & Visualization <a id=\"viz\"></a>\n\nVisualize the OCSF events as a formatted table and export as JSONL.\n\n**Scenario:** A production environment runs both LangChain and CrewAI workloads.\nWe collect all spans, normalize them through the pipeline, and export as JSONL\nfor ingestion into your SIEM."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-events"
   },
   "outputs": [],
   "source": "# ── Collect OCSF events from a mixed LangChain + CrewAI production workload ──\n\nall_spans = [\n    # LangChain: customer support chatbot\n    (\"ChatOpenAI\", {\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4o\",\n                    \"llm.token_count.prompt\": 380, \"llm.token_count.completion\": 120}),\n    (\"ChatAnthropic\", {\"ls_provider\": \"anthropic\", \"ls_model_name\": \"claude-sonnet-4-5-20250929\",\n                       \"llm.token_count.prompt\": 500, \"llm.token_count.completion\": 300}),\n    (\"AgentExecutor\", {\"langchain.agent.name\": \"support-agent\"}),\n    (\"VectorStoreRetriever\", {\"langchain.retriever.name\": \"support-kb-pinecone\", \"langchain.retriever.k\": 8}),\n    # CrewAI: security audit crew\n    (\"Crew Execution\", {\"crewai.agent.role\": \"security-manager\", \"crewai.crew.name\": \"security-audit-crew\"}),\n    (\"LLM Call claude-sonnet-4-5-20250929\", {\"crewai.llm.model\": \"claude-sonnet-4-5-20250929\", \"crewai.llm.input_tokens\": 1500}),\n    (\"Tool Execution cve_lookup\", {\"crewai.tool.name\": \"cve_lookup\", \"crewai.tool.duration_ms\": 1850.0}),\n    (\"Task Delegation\", {\"crewai.delegation.from_agent\": \"security-manager\", \"crewai.delegation.to_agent\": \"report-writer\"}),\n]\n\nprint(f\"{'Span Name':<40s} {'Vendor':<12s} {'Event Type':<14s} {'OCSF':>6s}\")\nprint(f\"{'-'*40} {'-'*12} {'-'*14} {'-'*6}\")\n\nocsf_events = []\nfor name, attrs in all_spans:\n    span = make_span(name, attrs)\n    result = vendor_mapper.normalize_span(span)\n    if result:\n        v, et, aa = result\n        uid = vendor_mapper.get_ocsf_class_uid(v, et) or \"?\"\n        print(f\"{name:<40s} {v:<12s} {et:<14s} {uid:>6}\")\n\n        norm_span = make_span(f\"{et} {name}\", aa)\n        ocsf_ev = ocsf_mapper.map_span(norm_span)\n        if ocsf_ev:\n            enriched = compliance_mapper.enrich_event(ocsf_ev, et.replace(\"inference\", \"model_inference\"))\n            ocsf_events.append(enriched)\n\nprint(f\"\\nTotal OCSF events generated: {len(ocsf_events)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-jsonl"
   },
   "outputs": [],
   "source": [
    "# Export events as JSONL (the format used by OCSF Exporter)\n",
    "import io\n",
    "\n",
    "jsonl_buffer = io.StringIO()\n",
    "for ev in ocsf_events:\n",
    "    line = json.dumps(ev.model_dump(exclude_none=True), default=str)\n",
    "    jsonl_buffer.write(line + \"\\n\")\n",
    "\n",
    "jsonl_content = jsonl_buffer.getvalue()\n",
    "\n",
    "print(\"OCSF JSONL Export\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Events:    {len(ocsf_events)}\")\n",
    "print(f\"  Size:      {len(jsonl_content):,} bytes\")\n",
    "print(f\"  Format:    JSONL (one OCSF event per line)\")\n",
    "print(f\"\\nFirst event (preview):\")\n",
    "first_event = json.loads(jsonl_content.split(\"\\n\")[0])\n",
    "preview_keys = {\"class_uid\", \"type_uid\", \"activity_id\", \"category_uid\",\n",
    "                \"severity_id\", \"status_id\", \"message\", \"time\"}\n",
    "preview = {k: v for k, v in first_event.items() if k in preview_keys}\n",
    "pp(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-stats"
   },
   "outputs": [],
   "source": [
    "# Event statistics\n",
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter()\n",
    "vendor_counts = Counter()\n",
    "\n",
    "for name, attrs in all_spans:\n",
    "    span = make_span(name, attrs)\n",
    "    result = vendor_mapper.normalize_span(span)\n",
    "    if result:\n",
    "        v, et, _ = result\n",
    "        uid = vendor_mapper.get_ocsf_class_uid(v, et)\n",
    "        class_name = class_map.get(uid, (f\"Class {uid}\",))[0] if uid else \"Unknown\"\n",
    "        class_counts[class_name] += 1\n",
    "        vendor_counts[v] += 1\n",
    "\n",
    "print(\"Event Distribution by OCSF Class\")\n",
    "print(\"=\" * 50)\n",
    "for cls, count in class_counts.most_common():\n",
    "    bar = '#' * (count * 5)\n",
    "    print(f\"  {cls:<25s} {bar} {count}\")\n",
    "\n",
    "print(f\"\\nEvent Distribution by Vendor\")\n",
    "print(\"=\" * 50)\n",
    "for vendor, count in vendor_counts.most_common():\n",
    "    bar = '#' * (count * 5)\n",
    "    print(f\"  {vendor:<12s} {bar} {count}\")\n",
    "\n",
    "print(f\"\\n  Total spans processed: {sum(vendor_counts.values())}\")\n",
    "print(f\"  Unique OCSF classes:   {len(class_counts)}\")\n",
    "print(f\"  Unique vendors:        {len(vendor_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated the full AITF pipeline:\n",
    "\n",
    "| Step | Component | What it Does |\n",
    "|------|-----------|-------------|\n",
    "| 1 | **VendorMapper** | Normalizes LangChain/CrewAI/custom telemetry to AITF conventions |\n",
    "| 2 | **OCSFMapper** | Converts OTel spans to OCSF Category 7 events (7001-7008) |\n",
    "| 3 | **ComplianceMapper** | Enriches events with controls from 8 regulatory frameworks |\n",
    "| 4 | **AgenticLogInstrumentor** | Structured security-context log entries per Table 10.1 |\n",
    "| 5 | **AIBOMGenerator** | AI Bill of Materials in AITF/CycloneDX/SPDX formats |\n",
    "| 6 | **Exporters** | OCSF JSONL, Immutable Audit Logs, CEF Syslog to SIEM |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Production deployment**: See `docs/deployment-guide.md` for 10 complete deployment examples\n",
    "- **Custom vendor mapping**: Create a JSON file for your agentic framework\n",
    "- **SIEM integration**: Use the CEF Syslog exporter for Splunk/QRadar/ArcSight\n",
    "- **Detection rules**: See `examples/detection-rules/` for Sigma and Splunk queries\n",
    "\n",
    "---\n",
    "\n",
    "*AITF — Security-first telemetry for AI systems*"
   ]
  }
 ]
}